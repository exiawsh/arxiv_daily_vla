[
    {
        "title": "CapNav: Benchmarking Vision Language Models on Capability-conditioned Indoor Navigation",
        "summary": "Vision-Language Models (VLMs) have shown remarkable progress in Vision-Language Navigation (VLN), offering new possibilities for navigation decision-making that could benefit both robotic platforms and human users. However, real-world navigation is inherently conditioned by the agent's mobility constraints. For example, a sweeping robot cannot traverse stairs, while a quadruped can. We introduce Capability-Conditioned Navigation (CapNav), a benchmark designed to evaluate how well VLMs can navigate complex indoor spaces given an agent's specific physical and operational capabilities. CapNav defines five representative human and robot agents, each described with physical dimensions, mobility capabilities, and environmental interaction abilities. CapNav provides 45 real-world indoor scenes, 473 navigation tasks, and 2365 QA pairs to test if VLMs can traverse indoor environments based on agent capabilities. We evaluate 13 modern VLMs and find that current VLM's navigation performance drops sharply as mobility constraints tighten, and that even state-of-the-art models struggle with obstacle types that require reasoning on spatial dimensions. We conclude by discussing the implications for capability-aware navigation and the opportunities for advancing embodied spatial reasoning in future VLMs. The benchmark is available at https://github.com/makeabilitylab/CapNav",
        "url": "http://arxiv.org/abs/2602.18424v1",
        "published_date": "2026-02-20T18:46:27+00:00",
        "updated_date": "2026-02-20T18:46:27+00:00",
        "categories": [
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Xia Su",
            "Ruiqi Chen",
            "Benlin Liu",
            "Jingwei Ma",
            "Zonglin Di",
            "Ranjay Krishna",
            "Jon Froehlich"
        ],
        "tldr": "The paper introduces CapNav, a new benchmark for evaluating Vision-Language Models (VLMs) on capability-conditioned indoor navigation, considering agents' physical and operational constraints. It reveals the limitations of current VLMs in handling mobility constraints and spatial reasoning for different agent types.",
        "tldr_zh": "该论文介绍了CapNav，一个用于评估视觉-语言模型（VLMs）在能力条件下室内导航的新基准，考虑了代理的物理和操作约束。研究揭示了当前VLMs在处理不同代理类型的移动约束和空间推理方面的局限性。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 10,
        "potential_impact_score": 9,
        "overall_priority_score": 9
    }
]