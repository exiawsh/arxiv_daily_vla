[
    {
        "title": "SC-MII: Infrastructure LiDAR-based 3D Object Detection on Edge Devices for Split Computing with Multiple Intermediate Outputs Integration",
        "summary": "3D object detection using LiDAR-based point cloud data and deep neural networks is essential in autonomous driving technology. However, deploying state-of-the-art models on edge devices present challenges due to high computational demands and energy consumption. Additionally, single LiDAR setups suffer from blind spots. This paper proposes SC-MII, multiple infrastructure LiDAR-based 3D object detection on edge devices for Split Computing with Multiple Intermediate outputs Integration. In SC-MII, edge devices process local point clouds through the initial DNN layers and send intermediate outputs to an edge server. The server integrates these features and completes inference, reducing both latency and device load while improving privacy. Experimental results on a real-world dataset show a 2.19x speed-up and a 71.6% reduction in edge device processing time, with at most a 1.09% drop in accuracy.",
        "url": "http://arxiv.org/abs/2601.07119v1",
        "published_date": "2026-01-12T01:17:01+00:00",
        "updated_date": "2026-01-12T01:17:01+00:00",
        "categories": [
            "cs.DC",
            "cs.CV"
        ],
        "authors": [
            "Taisuke Noguchi",
            "Takayuki Nishio",
            "Takuya Azumi"
        ],
        "tldr": "The paper presents SC-MII, a split computing framework for 3D object detection using multiple infrastructure LiDARs on edge devices. It achieves speed-up and reduced processing time on edge devices with minimal accuracy drop by processing initial DNN layers locally and integrating intermediate outputs on an edge server.",
        "tldr_zh": "该论文提出了SC-MII，一个使用多个基础设施激光雷达在边缘设备上进行3D目标检测的分割计算框架。通过在本地处理初始DNN层，并在边缘服务器上整合中间输出，它实现了加速和减少边缘设备处理时间，同时精度损失很小。",
        "relevance_score": 9,
        "novelty_claim_score": 7,
        "clarity_score": 8,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    },
    {
        "title": "Efficient Visual Question Answering Pipeline for Autonomous Driving via Scene Region Compression",
        "summary": "Autonomous driving increasingly relies on Visual Question Answering (VQA) to enable vehicles to understand complex surroundings by analyzing visual inputs and textual queries. Currently, a paramount concern for VQA in this domain is the stringent requirement for fast latency and real-time processing, as delays directly impact real-world safety in this safety-critical application. However, current state-of-the-art VQA models, particularly large vision-language models (VLMs), often prioritize performance over computational efficiency. These models typically process dense patch tokens for every frame, leading to prohibitive computational costs (FLOPs) and significant inference latency, especially with long video sequences. This focus limits their practical deployment in real-time autonomous driving scenarios. To tackle this issue, we propose an efficient VLM framework for autonomous driving VQA tasks, SRC-Pipeline. It learns to compress early frame tokens into a small number of high-level tokens while retaining full patch tokens for recent frames. Experiments on autonomous driving video question answering tasks show that our approach achieves 66% FLOPs reduction while maintaining comparable performance, enabling VLMs to operate more effectively in real-time, safety-critical autonomous driving settings.",
        "url": "http://arxiv.org/abs/2601.07092v1",
        "published_date": "2026-01-11T23:25:49+00:00",
        "updated_date": "2026-01-11T23:25:49+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Yuliang Cai",
            "Dongqiangzi Ye",
            "Zitian Chen",
            "Chongruo Wu"
        ],
        "tldr": "The paper introduces an efficient VQA pipeline, SRC-Pipeline, for autonomous driving that reduces FLOPs by compressing early frame tokens in VLMs, enabling real-time performance with comparable accuracy.",
        "tldr_zh": "该论文介绍了一种高效的VQA管道SRC-Pipeline，用于自动驾驶，通过压缩VLMs中早期帧的token来减少FLOPs，从而在保持相当精度的前提下实现实时性能。",
        "relevance_score": 9,
        "novelty_claim_score": 7,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    }
]