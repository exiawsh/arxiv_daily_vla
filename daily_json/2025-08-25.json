[
    {
        "title": "SEER-VAR: Semantic Egocentric Environment Reasoner for Vehicle Augmented Reality",
        "summary": "We present SEER-VAR, a novel framework for egocentric vehicle-based augmented\nreality (AR) that unifies semantic decomposition, Context-Aware SLAM Branches\n(CASB), and LLM-driven recommendation. Unlike existing systems that assume\nstatic or single-view settings, SEER-VAR dynamically separates cabin and road\nscenes via depth-guided vision-language grounding. Two SLAM branches track\negocentric motion in each context, while a GPT-based module generates\ncontext-aware overlays such as dashboard cues and hazard alerts. To support\nevaluation, we introduce EgoSLAM-Drive, a real-world dataset featuring\nsynchronized egocentric views, 6DoF ground-truth poses, and AR annotations\nacross diverse driving scenarios. Experiments demonstrate that SEER-VAR\nachieves robust spatial alignment and perceptually coherent AR rendering across\nvaried environments. As one of the first to explore LLM-based AR recommendation\nin egocentric driving, we address the lack of comparable systems through\nstructured prompting and detailed user studies. Results show that SEER-VAR\nenhances perceived scene understanding, overlay relevance, and driver ease,\nproviding an effective foundation for future research in this direction. Code\nand dataset will be made open source.",
        "url": "http://arxiv.org/abs/2508.17255v1",
        "published_date": "2025-08-24T08:45:15+00:00",
        "updated_date": "2025-08-24T08:45:15+00:00",
        "categories": [
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Yuzhi Lai",
            "Shenghai Yuan",
            "Peizheng Li",
            "Jun Lou",
            "Andreas Zell"
        ],
        "tldr": "The paper introduces SEER-VAR, an egocentric vehicle AR framework using semantic decomposition, Context-Aware SLAM, and LLMs for context-aware overlay generation, validated by a new EgoSLAM-Drive dataset. It improves scene understanding and driver ease.",
        "tldr_zh": "该论文介绍了一个名为SEER-VAR的以车辆为中心的增强现实框架，它利用语义分解、上下文感知SLAM和LLM来生成上下文感知的叠加层，并通过新的EgoSLAM-Drive数据集进行验证。该框架提高了场景理解和驾驶员的便利性。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    }
]